{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9918c76-2211-4795-9556-370d567280be",
   "metadata": {},
   "source": [
    "Make a small curriculum of miniature fly datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6323a4e4-88d4-4b2f-a3c8-fd8007c05461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import fftconvolve\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af24c0c8-6ded-4c7c-b8c4-4ee054ebc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 30.03\n",
    "DT = 1/FPS\n",
    "\n",
    "FSTRAIN = 'data_raw/fly/strains.csv'\n",
    "\n",
    "TARG_BHV = 'MTN'\n",
    "TWDWS = [.03, 1, 60]\n",
    "TARGS = [f'{TARG_BHV}_MN_{twdw}' for twdw in TWDWS]\n",
    "\n",
    "STRAINS = ['NM91', 'ZH23']\n",
    "STRAIN_KEY = '_'.join(STRAINS).lower()\n",
    "\n",
    "MSTRAINS = [(pd.read_csv(FSTRAIN)['STRAIN'] == strain) for strain in STRAINS]\n",
    "MSTRAIN = np.any(MSTRAINS, axis=0)\n",
    "ISTRAIN = MSTRAIN.nonzero()[0]\n",
    "\n",
    "NTRIAL = MSTRAIN.sum()\n",
    "\n",
    "# TAU_R = 1\n",
    "TAU_R = 60\n",
    "\n",
    "N = 20\n",
    "PARAMS = {\n",
    "    'TAU_R': np.random.uniform(TAU_R, TAU_R, N),  # seconds\n",
    "    'TAU_A': np.random.uniform(.1, 2, N),  # seconds\n",
    "    'X_S': np.random.uniform(0, 1, N),\n",
    "    'X_P': np.random.uniform(0, 1, N),\n",
    "}\n",
    "\n",
    "LOOK_BACK = 500  # frames (30 FPS)\n",
    "\n",
    "FDECIM = .005  # how much of the original data to actually keep (1,548,531 samples available total)\n",
    "\n",
    "PFX = f'data_s5/fly_curric_mini/lookback_{LOOK_BACK}_tau_r_{TAU_R}'\n",
    "\n",
    "if not os.path.exists(PFX):\n",
    "    os.makedirs(PFX)\n",
    "    os.makedirs(os.path.join(PFX, 'scrambled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973402f7-a470-4c33-8c9a-add3a9260d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smlt_ma(i_s, i_p, params, dt):\n",
    "    \"\"\"MA: Multiplicative adaptive neuron.\"\"\"\n",
    "    tau_rs = params['TAU_R']\n",
    "    tau_as = params['TAU_A']\n",
    "    x_ss = params['X_S']\n",
    "    x_ps = params['X_P']\n",
    "    \n",
    "    n = len(tau_rs)\n",
    "    \n",
    "    t = np.arange(len(i_s))*dt\n",
    "    rs = np.nan*np.zeros((len(t), n))\n",
    "    \n",
    "    rs[0, :] = 0\n",
    "    a_s = np.zeros(n)\n",
    "    a_p = np.zeros(n)\n",
    "    \n",
    "    for ct, t_ in enumerate(t[1:], 1):\n",
    "        a_s += ((dt/tau_as) * (-a_s + i_s[ct]))\n",
    "        a_p += ((dt/tau_as) * (-a_p + i_p[ct]))\n",
    "        dr = (dt/tau_rs) * (-rs[ct-1, :] + (1 - a_s)*x_ss*i_s[ct] + (1 - a_p)*x_ps*i_p[ct])\n",
    "        rs[ct, :] = rs[ct-1, :] + dr\n",
    "    \n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676f7f4e-f232-4224-9e5b-390ad35bdf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................."
     ]
    }
   ],
   "source": [
    "columns = ['fmtn', 'session', 'frame', 'song']\n",
    "df_full = pd.read_csv('data_raw/fly/c_song_f_behav_true.csv')\n",
    "\n",
    "df_trs = [df_full[df_full.ID == i] for i in ISTRAIN]\n",
    "del df_full\n",
    "\n",
    "paths_all = []\n",
    "\n",
    "data_dicts = []\n",
    "data_dicts_scrambled = []\n",
    "\n",
    "for df_tr in df_trs:\n",
    "    sys.stdout.write('.')\n",
    "\n",
    "    frames = np.array(df_tr['FRAME']).astype(int)\n",
    "    song = np.repeat('Q', len(df_tr))\n",
    "\n",
    "    song[np.array(df_tr['S']) == 1] = 'S'\n",
    "    song[np.array(df_tr['P']) == 1] = 'P'\n",
    "\n",
    "    song = ''.join(song)\n",
    "\n",
    "    i_s = (np.array(df_tr['S']) == 1).astype(float)\n",
    "    i_p = (np.array(df_tr['P']) == 1).astype(float)\n",
    "\n",
    "    rs = smlt_ma(i_s, i_p, PARAMS, DT)\n",
    "    fmtn = np.mean(rs, axis=1)\n",
    "\n",
    "    fmtn_scrambled = fmtn[np.random.permutation(len(fmtn))]\n",
    "\n",
    "    for cframe, frame in enumerate(frames):\n",
    "        \n",
    "        song_till_now = song[:cframe]\n",
    "        \n",
    "        if len(song_till_now) < LOOK_BACK:\n",
    "            prefix = ''.join(np.repeat('Q', LOOK_BACK-len(song_till_now)))\n",
    "            song_till_now = prefix+song_till_now\n",
    "            \n",
    "        song_seg = song_till_now[-LOOK_BACK:]\n",
    "        \n",
    "        data_dict = {\n",
    "            'fmtn': fmtn[cframe],\n",
    "            'session': np.array(df_tr['ID']).astype(int)[cframe],\n",
    "            'frame': frame,\n",
    "            'song': song_seg,\n",
    "        }\n",
    "\n",
    "        data_dicts.append(data_dict)\n",
    "        \n",
    "        data_dict_scrambled = {\n",
    "            'fmtn_scrambled': fmtn_scrambled[cframe],\n",
    "            'session': np.array(df_tr['ID']).astype(int)[cframe],\n",
    "            'frame': frame,\n",
    "            'song': song_seg,\n",
    "        }\n",
    "        \n",
    "        data_dicts_scrambled.append(data_dict_scrambled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18416767-59d1-400e-b21d-456029f70d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548531"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416016d9-23a6-4c45-8c4e-a02a1cc012bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# decimate the data dict\n",
    "idx_decim = (np.random.rand(len(data_dicts)) < FDECIM).nonzero()[0]\n",
    "data_dicts_dec = [data_dict for idx, data_dict in enumerate(data_dicts) if idx in idx_decim]\n",
    "data_dicts_scrambled_dec = [data_dict for idx, data_dict in enumerate(data_dicts_scrambled) if idx in idx_decim]\n",
    "\n",
    "print('')\n",
    "df = pd.DataFrame(columns=columns, data=data_dicts_dec)\n",
    "path = os.path.join(PFX, 'full.tsv')\n",
    "df.to_csv(path, sep='\\t', index=False, header=False)\n",
    "\n",
    "df_scrambled = pd.DataFrame(columns=columns, data=data_dicts_scrambled_dec)\n",
    "path_scrambled = os.path.join(PFX, 'scrambled', 'full.tsv')\n",
    "df_scrambled.to_csv(path_scrambled, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c39935c-f498-43a3-823d-515186893a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data_s5/fly_curric_mini/lookback_500_tau_r_60/full.tsv...\n",
      "Loading data_s5/fly_curric_mini/lookback_500_tau_r_60/scrambled/full.tsv...\n"
     ]
    }
   ],
   "source": [
    "for path_ in [path, path_scrambled]:\n",
    "    sys.stdout.write(f'Loading {path_}...\\n')\n",
    "    df = pd.read_csv(path_, sep='\\t', header=None)\n",
    "\n",
    "    # split into training, val, and test (here val and test are same)\n",
    "    nrow_train = int(len(df)*.8)\n",
    "    df_train = df.iloc[:nrow_train, :]\n",
    "    df_val = df.iloc[nrow_train:, :]\n",
    "    df_test = df.iloc[nrow_train:, :]\n",
    "\n",
    "    df_train.to_csv(path_[:-8] + 'train.tsv', sep='\\t', header=False, index=False)\n",
    "    df_val.to_csv(path_[:-8] + 'eval.tsv', sep='\\t', header=False, index=False)\n",
    "    df_test.to_csv(path_[:-8] + 'test.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b997f274-039f-4319-8780-073bddba261f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s5-gpu [~/.conda/envs/s5-gpu/]",
   "language": "python",
   "name": "conda_s5-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
