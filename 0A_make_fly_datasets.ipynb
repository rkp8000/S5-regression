{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6323a4e4-88d4-4b2f-a3c8-fd8007c05461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import fftconvolve\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af24c0c8-6ded-4c7c-b8c4-4ee054ebc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "FSTRAIN = 'data_raw/fly/strains.csv'\n",
    "\n",
    "TARG_BHV = 'MTN'\n",
    "TWDWS = [.03, 1, 60]\n",
    "TARGS = [f'{TARG_BHV}_MN_{twdw}' for twdw in TWDWS]\n",
    "\n",
    "STRAINS = ['NM91', 'ZH23']\n",
    "STRAIN_KEY = '_'.join(STRAINS).lower()\n",
    "\n",
    "MSTRAINS = [(pd.read_csv(FSTRAIN)['STRAIN'] == strain) for strain in STRAINS]\n",
    "MSTRAIN = np.any(MSTRAINS, axis=0)\n",
    "ISTRAIN = MSTRAIN.nonzero()[0]\n",
    "\n",
    "NTRIAL = MSTRAIN.sum()\n",
    "\n",
    "TAU_S = 10\n",
    "TAU_P = 20\n",
    "TH = np.arange(5*TAU_P, dtype=float)\n",
    "H_S = np.exp(-TH/TAU_S)/20\n",
    "H_P = np.exp(-TH/TAU_P)/20\n",
    "\n",
    "FDECIM = .005  # how much of the original data to actually keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3143f9-f319-4375-a1be-faeee9a17881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_filt(song):\n",
    "    s = np.array([char for char in song]) == 'S'\n",
    "    p = np.array([char for char in song]) == 'P'\n",
    "    temp = fftconvolve(s, H_S, mode='full')[:len(s)] + fftconvolve(p, H_P, mode='full')[:len(p)]\n",
    "    return np.concatenate([[0], temp[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ab8edc-8724-4d71-bfa5-de64f20dfeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PFXS = ['clf', 'clf_scrambled', 'rgr', 'rgr_scrambled']\n",
    "LOOK_BACKS = [100]\n",
    "# LOOK_BACKS = [100, 1000, 2000, 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c567b3-2d97-41a8-96ba-daf3a9c99008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback=100.......................................................................................\n",
      "lookback=100.......................................................................................\n",
      "lookback=100.......................................................................................\n",
      "lookback=100.......................................................................................\n"
     ]
    }
   ],
   "source": [
    "columns = ['fmtn', 'session', 'frame', 'song']\n",
    "df_full = pd.read_csv('data_raw/fly/c_song_f_behav_true.csv')\n",
    "\n",
    "df_trs = [df_full[df_full.ID == i] for i in ISTRAIN]\n",
    "del df_full\n",
    "\n",
    "paths_all = []\n",
    "\n",
    "for pfx in PFXS:\n",
    "    for look_back in LOOK_BACKS:\n",
    "        sys.stdout.write(f'lookback={look_back}')\n",
    "        data_dicts = []\n",
    "\n",
    "        for df_tr in df_trs:\n",
    "            sys.stdout.write('.')\n",
    "\n",
    "            frames = np.array(df_tr['FRAME']).astype(int)\n",
    "            song = np.repeat('Q', len(df_tr))\n",
    "\n",
    "            song[np.array(df_tr['S']) == 1] = 'S'\n",
    "            song[np.array(df_tr['P']) == 1] = 'P'\n",
    "\n",
    "            song = ''.join(song)\n",
    "\n",
    "            if pfx.startswith('clf'):\n",
    "                fmtn = (exp_filt(song) >= 1/20).astype(int)\n",
    "            elif pfx.startswith('rgr'):\n",
    "                fmtn = exp_filt(song)\n",
    "                fmtn += .1*np.random.randn(len(fmtn))*np.std(fmtn)  # add some wee noise\n",
    "            if pfx.endswith('scrambled'):\n",
    "                fmtn = fmtn[np.random.permutation(len(fmtn))]\n",
    "\n",
    "            for cframe, frame in enumerate(frames):\n",
    "                song_till_now = song[:cframe]\n",
    "                if len(song_till_now) < look_back:\n",
    "                    prefix = ''.join(np.repeat('Q', look_back-len(song_till_now)))\n",
    "                    song_till_now = prefix+song_till_now\n",
    "                song_seg = song_till_now[-look_back:]\n",
    "                data_dict = {\n",
    "                    'fmtn': fmtn[cframe],\n",
    "                    'session': np.array(df_tr['ID']).astype(int)[cframe],\n",
    "                    'frame': frame,\n",
    "                    'song': song_seg}\n",
    "\n",
    "                data_dicts.append(data_dict)\n",
    "                \n",
    "        # decimate the data dict\n",
    "        data_dicts_dec = [data_dict for data_dict in data_dicts if np.random.rand() < FDECIM]\n",
    "\n",
    "        print('')\n",
    "        df = pd.DataFrame(columns=columns, data=data_dicts_dec)\n",
    "        path = f'data_s5/fly_mini/{pfx}_lookback_{look_back}_fdecim_{FDECIM}.tsv'\n",
    "        df.to_csv(path, sep='\\t', index=False, header=False)\n",
    "        \n",
    "        paths_all.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c39935c-f498-43a3-823d-515186893a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data_s5/fly_mini/clf_lookback_100_fdecim_0.005.tsv...\n",
      "Loading data_s5/fly_mini/clf_scrambled_lookback_100_fdecim_0.005.tsv...\n",
      "Loading data_s5/fly_mini/rgr_lookback_100_fdecim_0.005.tsv...\n",
      "Loading data_s5/fly_mini/rgr_scrambled_lookback_100_fdecim_0.005.tsv...\n"
     ]
    }
   ],
   "source": [
    "for path in paths_all:\n",
    "    sys.stdout.write(f'Loading {path}...\\n')\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "\n",
    "    # split into training, val, and test (here val and test are same)\n",
    "    nrow_train = int(len(df)*.8)\n",
    "    df_train = df.iloc[:nrow_train, :]\n",
    "    df_val = df.iloc[nrow_train:, :]\n",
    "    df_test = df.iloc[nrow_train:, :]\n",
    "\n",
    "    df_train.to_csv(path[:-4] + '.train.tsv', sep='\\t', header=False, index=False)\n",
    "    df_val.to_csv(path[:-4] + '.eval.tsv', sep='\\t', header=False, index=False)\n",
    "    df_test.to_csv(path[:-4] + '.test.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67c199-5463-46ed-8195-9c186756da30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s5-gpu [~/.conda/envs/s5-gpu/]",
   "language": "python",
   "name": "conda_s5-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
