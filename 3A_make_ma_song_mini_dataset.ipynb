{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9918c76-2211-4795-9556-370d567280be",
   "metadata": {},
   "source": [
    "Make a test dataset converting song to artificial fmtn via MA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6323a4e4-88d4-4b2f-a3c8-fd8007c05461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import fftconvolve\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af24c0c8-6ded-4c7c-b8c4-4ee054ebc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 30.03\n",
    "DT = 1/FPS\n",
    "\n",
    "FSTRAIN = 'data_raw/fly/strains.csv'\n",
    "\n",
    "TARG_BHV = 'MTN'\n",
    "TWDWS = [.03, 1, 60]\n",
    "TARGS = [f'{TARG_BHV}_MN_{twdw}' for twdw in TWDWS]\n",
    "\n",
    "STRAINS = ['NM91', 'ZH23']\n",
    "STRAIN_KEY = '_'.join(STRAINS).lower()\n",
    "\n",
    "MSTRAINS = [(pd.read_csv(FSTRAIN)['STRAIN'] == strain) for strain in STRAINS]\n",
    "MSTRAIN = np.any(MSTRAINS, axis=0)\n",
    "ISTRAIN = MSTRAIN.nonzero()[0]\n",
    "\n",
    "NTRIAL = MSTRAIN.sum()\n",
    "\n",
    "N = 20\n",
    "PARAMS = {\n",
    "    'TAU_R': np.random.uniform(.5, 1, N),\n",
    "    'TAU_A': np.random.uniform(.1, 1, N),\n",
    "    'X_S': np.random.uniform(0, 1, N),\n",
    "    'X_P': np.random.uniform(0, 1, N),\n",
    "}\n",
    "\n",
    "LOOK_BACKS = [100]\n",
    "\n",
    "FDECIM = .005  # how much of the original data to actually keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973402f7-a470-4c33-8c9a-add3a9260d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smlt_ma(i_s, i_p, params, dt):\n",
    "    \"\"\"MA: Multiplicative adaptive neuron.\"\"\"\n",
    "    tau_rs = params['TAU_R']\n",
    "    tau_as = params['TAU_A']\n",
    "    x_ss = params['X_S']\n",
    "    x_ps = params['X_P']\n",
    "    \n",
    "    n = len(tau_rs)\n",
    "    \n",
    "    t = np.arange(len(i_s))*dt\n",
    "    rs = np.nan*np.zeros((len(t), n))\n",
    "    \n",
    "    rs[0, :] = 0\n",
    "    a_s = np.zeros(n)\n",
    "    a_p = np.zeros(n)\n",
    "    \n",
    "    for ct, t_ in enumerate(t[1:], 1):\n",
    "        a_s += ((dt/tau_as) * (-a_s + i_s[ct]))\n",
    "        a_p += ((dt/tau_as) * (-a_p + i_p[ct]))\n",
    "        dr = (dt/tau_rs) * (-rs[ct-1, :] + (1 - a_s)*x_ss*i_s[ct] + (1 - a_p)*x_ps*i_p[ct])\n",
    "        rs[ct, :] = rs[ct-1, :] + dr\n",
    "    \n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ab8edc-8724-4d71-bfa5-de64f20dfeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PFXS = ['rgr', 'rgr_scrambled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c567b3-2d97-41a8-96ba-daf3a9c99008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback=100.......................................................................................\n",
      "lookback=100.......................................................................................\n"
     ]
    }
   ],
   "source": [
    "columns = ['fmtn', 'session', 'frame', 'song']\n",
    "df_full = pd.read_csv('data_raw/fly/c_song_f_behav_true.csv')\n",
    "\n",
    "df_trs = [df_full[df_full.ID == i] for i in ISTRAIN]\n",
    "del df_full\n",
    "\n",
    "paths_all = []\n",
    "\n",
    "for pfx in PFXS:\n",
    "    for look_back in LOOK_BACKS:\n",
    "        sys.stdout.write(f'lookback={look_back}')\n",
    "        data_dicts = []\n",
    "\n",
    "        for df_tr in df_trs:\n",
    "            sys.stdout.write('.')\n",
    "\n",
    "            frames = np.array(df_tr['FRAME']).astype(int)\n",
    "            song = np.repeat('Q', len(df_tr))\n",
    "\n",
    "            song[np.array(df_tr['S']) == 1] = 'S'\n",
    "            song[np.array(df_tr['P']) == 1] = 'P'\n",
    "\n",
    "            song = ''.join(song)\n",
    "\n",
    "            i_s = (np.array(df_tr['S']) == 1).astype(float)\n",
    "            i_p = (np.array(df_tr['P']) == 1).astype(float)\n",
    "            \n",
    "            rs = smlt_ma(i_s, i_p, PARAMS, DT)\n",
    "            fmtn = np.mean(rs, axis=1)\n",
    "            \n",
    "            if pfx.endswith('scrambled'):\n",
    "                fmtn = fmtn[np.random.permutation(len(fmtn))]\n",
    "\n",
    "            for cframe, frame in enumerate(frames):\n",
    "                song_till_now = song[:cframe]\n",
    "                if len(song_till_now) < look_back:\n",
    "                    prefix = ''.join(np.repeat('Q', look_back-len(song_till_now)))\n",
    "                    song_till_now = prefix+song_till_now\n",
    "                song_seg = song_till_now[-look_back:]\n",
    "                data_dict = {\n",
    "                    'fmtn': fmtn[cframe],\n",
    "                    'session': np.array(df_tr['ID']).astype(int)[cframe],\n",
    "                    'frame': frame,\n",
    "                    'song': song_seg}\n",
    "\n",
    "                data_dicts.append(data_dict)\n",
    "                \n",
    "        # decimate the data dict\n",
    "        data_dicts_dec = [data_dict for data_dict in data_dicts if np.random.rand() < FDECIM]\n",
    "\n",
    "        print('')\n",
    "        df = pd.DataFrame(columns=columns, data=data_dicts_dec)\n",
    "        path = f'data_s5/fly_mini_ma/{pfx}_lookback_{look_back}.tsv'\n",
    "        df.to_csv(path, sep='\\t', index=False, header=False)\n",
    "        \n",
    "        paths_all.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c39935c-f498-43a3-823d-515186893a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data_s5/fly_mini_ma/rgr_lookback_100.tsv...\n",
      "Loading data_s5/fly_mini_ma/rgr_scrambled_lookback_100.tsv...\n"
     ]
    }
   ],
   "source": [
    "for path in paths_all:\n",
    "    sys.stdout.write(f'Loading {path}...\\n')\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "\n",
    "    # split into training, val, and test (here val and test are same)\n",
    "    nrow_train = int(len(df)*.8)\n",
    "    df_train = df.iloc[:nrow_train, :]\n",
    "    df_val = df.iloc[nrow_train:, :]\n",
    "    df_test = df.iloc[nrow_train:, :]\n",
    "\n",
    "    df_train.to_csv(path[:-4] + '.train.tsv', sep='\\t', header=False, index=False)\n",
    "    df_val.to_csv(path[:-4] + '.eval.tsv', sep='\\t', header=False, index=False)\n",
    "    df_test.to_csv(path[:-4] + '.test.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67c199-5463-46ed-8195-9c186756da30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s5-gpu [~/.conda/envs/s5-gpu/]",
   "language": "python",
   "name": "conda_s5-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
