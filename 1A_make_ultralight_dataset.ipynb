{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f868bd-cd83-43ea-bd6b-25af5148a1a3",
   "metadata": {},
   "source": [
    "# Create an ultralight testing dataset\n",
    "\n",
    "Regression target is number of S's in a length-9 token sequence, divided by 9. For classification threshold at .5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6323a4e4-88d4-4b2f-a3c8-fd8007c05461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy as copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import fftconvolve\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ab8edc-8724-4d71-bfa5-de64f20dfeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QPQPQPSPQ 0.1111111111111111\n",
      "SSSSQSSSS 0.8888888888888888\n",
      "SSSSSSSSS 1.0\n",
      "SSSSQSSSS 0.8888888888888888\n",
      "SSSSSSSSQ 0.8888888888888888\n",
      "QPSPQSSSQ 0.4444444444444444\n",
      "QSQPSSQPQ 0.3333333333333333\n",
      "QPQPQPQPQ 0.0\n",
      "QPQSQPQSS 0.3333333333333333\n",
      "SSQSSSSSS 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "LOOK_BACK = 9\n",
    "\n",
    "NSEQ = 1000\n",
    "\n",
    "seqs = []\n",
    "targs = []\n",
    "\n",
    "for cseq in range(NSEQ):\n",
    "    num_s = np.random.randint(0, LOOK_BACK+1)\n",
    "    seq = ((LOOK_BACK-1)//2)*['Q', 'P'] + ['Q']\n",
    "    for idx_s in np.random.permutation(LOOK_BACK)[:num_s]:\n",
    "        seq[idx_s] = 'S'\n",
    "        \n",
    "    seqs.append(''.join(seq))\n",
    "    \n",
    "    targ = num_s/LOOK_BACK\n",
    "    targs.append(targ)\n",
    "\n",
    "for idx_print in np.random.permutation(NSEQ)[:10]:\n",
    "    print(seqs[idx_print], targs[idx_print])\n",
    "    \n",
    "seqs = np.array(seqs)\n",
    "targs = np.array(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a63349-97e5-4cc0-8094-b39d29d9e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PFXS = ['clf', 'clf_scrambled', 'rgr', 'rgr_scrambled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c567b3-2d97-41a8-96ba-daf3a9c99008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pfx: clf\n",
      "pfx: clf_scrambled\n",
      "pfx: rgr\n",
      "pfx: rgr_scrambled\n"
     ]
    }
   ],
   "source": [
    "columns = ['fmtn', 'session', 'frame', 'song']\n",
    "\n",
    "paths_all = []\n",
    "\n",
    "for pfx in PFXS:\n",
    "    sys.stdout.write(f'pfx: {pfx}')\n",
    "    \n",
    "    songs = copy(seqs)\n",
    "    fmtns = copy(targs)\n",
    "    \n",
    "    if pfx.startswith('clf'):\n",
    "        fmtns = (fmtns > .5).astype(int)\n",
    "    if pfx.endswith('scrambled'):\n",
    "        fmtns = fmtns[np.random.permutation(NSEQ)]\n",
    "        \n",
    "    data_dicts = []\n",
    "    \n",
    "    for song, fmtn in zip(songs, fmtns):\n",
    "        data_dict = {'fmtn': fmtn, 'session': 0, 'frame': 0, 'song': song}\n",
    "        data_dicts.append(data_dict)\n",
    "\n",
    "    print('')\n",
    "    df = pd.DataFrame(columns=columns, data=data_dicts)\n",
    "    path = f'data_s5/ultralight/{pfx}_lookback_{LOOK_BACK}.tsv'\n",
    "    df.to_csv(path, sep='\\t', index=False, header=False)\n",
    "\n",
    "    paths_all.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c39935c-f498-43a3-823d-515186893a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data_s5/ultralight/clf_lookback_9.tsv...\n",
      "Loading data_s5/ultralight/clf_scrambled_lookback_9.tsv...\n",
      "Loading data_s5/ultralight/rgr_lookback_9.tsv...\n",
      "Loading data_s5/ultralight/rgr_scrambled_lookback_9.tsv...\n"
     ]
    }
   ],
   "source": [
    "for path in paths_all:\n",
    "    sys.stdout.write(f'Loading {path}...\\n')\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "\n",
    "    # split into training, val, and test (here val and test are same)\n",
    "    nrow_train = int(len(df)*.8)\n",
    "    df_train = df.iloc[:nrow_train, :]\n",
    "    df_val = df.iloc[nrow_train:, :]\n",
    "    df_test = df.iloc[nrow_train:, :]\n",
    "\n",
    "    df_train.to_csv(path[:-4] + '.train.tsv', sep='\\t', header=False, index=False)\n",
    "    df_val.to_csv(path[:-4] + '.eval.tsv', sep='\\t', header=False, index=False)\n",
    "    df_test.to_csv(path[:-4] + '.test.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67c199-5463-46ed-8195-9c186756da30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s5-gpu [~/.conda/envs/s5-gpu/]",
   "language": "python",
   "name": "conda_s5-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
